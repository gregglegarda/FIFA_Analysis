---
title: "FIFA_Analysis"
author: "CrystalMeth"
date: "Nov 19, 2019"
output:
  html_document:
    number_sectiond: yes
    toc: yes
    toc_float:
      collapsed: no
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = F)
options(scientific=T, digits = 3) 
```

```{r basicfcn, include=F}
# can add quietly=T option to the require() function
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

### Introduction

### FIFA Dataset 
=======
### Chapter 1: Introduction (Curtis)
FIFA 19 is a football (soccer) simulation video game developed by EAsports. It is a part of the FIFA series, which has been produced for over 20 years. Every year, a FIFA game is released, FIFA 2019 was released in 2018, at the beginning of the 2018-2019 season of major soccer leagues in Europe. FIFA 2019 has over 31 leagues and more than 720 playable teams from around the world. This game contains an enormous amount of data which demonstrates different ratings and information of players, ranging from age and nationality to skillsets such as finishing, kicking, heading, tackling and even weak-foot strength. 

How do they complete such a huge database of ratings for every single player from all the licensed leagues? EA Sports employs a team of 25 EA Producers and 400 outside data contributors, who are led by the Head of Data Collection & Licensing. This team is responsible for ensuring all player data is up to date, while a community of over 6,000 FIFA Data Reviewers or Talent Scouts from all over the world are constantly providing suggestions and alterations to the database. 

In this project, our team will try to catch hold of several insights from the dataset using EDA and other statistical analysis methods. 

Sources
https://www.ea.com/games/fifa
https://www.fifplay.com/fifa-19-leagues-and-teams/
https://www.goal.com/en-ae/news/fifa-player-ratings-explained-how-are-the-card-number-stats/1hszd2fgr7wgf1n2b2yjdpgynu



### Chapter 2: Description of Data
>>>>>>> c62f819f41a0539212ee1fa7fe260fdac0397553

#### 2.1 Source Data

In this study, the CSV data file comes from FIFA 2019 database (https://www.kaggle.com/karangadiya/fifa19). This dataset contains 18,207 soccer player information in FIFA 2019 with 89 variables such as name, age, nationality, skill level, potential, club, transferred value, wage, preferred foot, body type, position in the field, height, and weight.	

```{r source data, include=F}
library(readr)
fifa <- read_csv("data.csv")
str(fifa)

```

<<<<<<< HEAD
### Preparing and exploring the data (include =F)
```{r echo=FALSE, include= FALSE}

```

## Smart Question 1 (BIN)
### How can we predict a dream team by determining the optimal skills(strength, heading, kick, jump) and vcharacteristics( leftfooted, bodytype, vision)in certain positions? And who would be the best players for the position?
=======
### 2.2 Geographic Coverage of Data

To do a basic data visualization, latitude and longitude in the dataset are used to draw the map, which is plotted by leaflet library in R. 

#### The number of soccer players in each area of the world

```{r map1, include=F}
library(dplyr)
library(ggplot2)
library(maps)
overall_fifa <- fifa %>% 
  group_by(Nationality) %>% 
  summarise(Count = n(), 
            Avg_Overall = mean(Overall),
            Avg_Potential = mean(Potential),
            Avg_Pot_Diff = mean(Potential-Overall))
worldmap = map_data("world")
merged_fifa <- merge(x = worldmap, y = overall_fifa, by.x = "region", by.y = "Nationality", all.x = TRUE) %>% arrange(order)

```

```{r map1a, echo=F}
ggplot(data = merged_fifa, aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = Count)) +
  labs(fill='Number of players')


```

#### The average skill level of soccer players in each area of the world (level: 0-100)

```{r map2, echo=F}
overall_fifa <- fifa %>% 
  group_by(Nationality) %>% 
  summarise(Count = n(), 
            Avg_Overall = mean(Overall),
            Avg_Potential = mean(Potential),
            Avg_Pot_Diff = mean(Potential-Overall)) %>%
  filter(Count > 45)
ggplot(data = merged_fifa, aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = Avg_Overall)) +
  labs(fill='Average skill')


```


### Smart Question 1 (BIN)
#### How can we predict a dream team by determining the optimal skills(strength, heading, kick, jump) and vcharacteristics( leftfooted, bodytype, vision)in certain positions? And who would be the best players for the position?
>>>>>>> c62f819f41a0539212ee1fa7fe260fdac0397553

```{r S1, echo=FALSE, include=TRUE}
#TEST used: Classification (KNN, Decision trees)
```


```{r}
library(tidyverse)
library(ggplot2)

```


```{r}
fifa <- read.csv('data.csv')
```


```{r}
positions_names <- c("LS", "ST", "RS", "LW", "LF", "CF", "RF", "RW", "LAM", "CAM", "RAM", "LM", "LCM", "CM", "RCM", "RM", "LWB", "LDM", "CDM", "RDM", "RWB", "LB", "LCB", "CB", "RCB", "RB")
skills_names <- c("Crossing", "Finishing", "HeadingAccuracy", "ShortPassing", "Volleys", "Dribbling", "Curve", "FKAccuracy", "LongPassing", "BallControl", "Acceleration", "SprintSpeed", "Agility", "Reactions", "Balance", "ShotPower", "Jumping", "Stamina", "Strength", "LongShots", "Aggression", "Interceptions", "Positioning", "Vision", "Penalties", "Composure", "Marking", "StandingTackle", "SlidingTackle", "GKDiving", "GKHandling", "GKKicking", "GKPositioning", "GKReflexes")
```

```{r}
for (position in positions_names) {
  fifa[position] <- lapply(fifa[position], function(rating){
    as.integer(substr(rating, 0, 2))
  })
}
```


```{r}
fifa_players <- na.omit(fifa[c(positions_names, skills_names)])
```


```{r}
middle <- c("LAM", "CAM", "RAM", "LM", "LCM", "CM", "RCM", "RM", "LDM", "CDM", "RDM")
left <- c("LS", "LW", "LF", "LAM", "LM", "LCM", "LWB", "LDM", "LB", "LCB")
right <- c("RS", "RF", "RW", "RAM", "RCM", "RM", "RDM", "RWB", "RCB", "RB")
```


```{r}
middle_players <- fifa_players[c(middle, skills_names)]
left_players <- fifa_players[c(left, skills_names)]
right_players <- fifa_players[c(right, skills_names)]
```
```{r}
head(middle_players)

```

```{r}
middle_players$value <- (middle_players$LAM + middle_players$CAM + middle_players$RAM + middle_players$LM + middle_players$LCM + middle_players$CM + middle_players$RCM + middle_players$RM + middle_players$LDM + middle_players$CDM + middle_players$RDM)/11
middle_players$value <- round(middle_players$value)
head(middle_players)
```


```{r}
middle_players_skills <- middle_players[-c(1:11, 46)]
head(middle_players_skills)
```

```{r}
middle_players_skills_scale = data.frame(scale(middle_players_skills))
head(middle_players_skills_scale)
```




```{r}
mps.pr.out =prcomp(middle_players_skills_scale, scale =TRUE)
summary(mps.pr.out)
mps.pr.out$rotation
```

```{r}
biplot(mps.pr.out, scale = 0)
```


```{r}
plot(mps.pr.out, type="l")
```

```{r}
mps.pr.var <- (mps.pr.out$sdev^2)
mps.pve <- mps.pr.var/sum(mps.pr.var)
plot(cumsum(mps.pve), xlab="Principal Component (standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b")
```



```{r}
head(middle_players_skills_scale)
```

```{r}
mps.pr.out$rotation
```

```{r}
mp.pca <- cbind(middle_players[46], data.frame(mps.pr.out$x))
head(mp.pca)
```

```{r}
mp.pcr1 <- lm(value ~., data = mp.pca)
summary(mp.pcr1)
```

```{r}
mp.pcr2 <- lm(value ~ PC1 + PC2 + PC3, data = mp.pca)
summary(mp.pcr2)
```

```{r}
anova(mp.pcr1, mp.pcr2)
```

# Smart Question 2 (RUSSELL)
## What variables contribute most to a player’s skill in penalty shots?
```{r S2, echo=FALSE, include=TRUE}
loadPkg("pls")

#Reload data
data <- read.csv("data.csv", check.names = FALSE, stringsAsFactors = FALSE)

#drop NAs
fifa <- na.omit(data)

#keep numeric variables only
fifa <- fifa[, !sapply(fifa, is.character)]

#drop ID variable
fifa <- fifa[, c(-1, -2)]
```
To begin the analysis, we drop all character variables and delete missing values. Additionally we drop the ID variable as it provides no usable information for our analysis. 


```{r EDA, echo=FALSE, include=TRUE}
library(corrplot)
barcolors = c("green", "violet", "orange", "blue", "pink", "red", "yellow", "cyan")

#subset data
fifacols <- c("Penalties", "Aggression","Age", "Stamina","ShotPower","Balance", "BallControl","LongPassing","HeadingAccuracy", "Strength")
fifa <- fifa[fifacols]

#histogram of Penalties
summary(fifa$Penalties)
sd(fifa$Penalties)
hist(fifa$Penalties, main="Histogram of Penalties", xlab="Skill in Penalties", ylab="Frequency", col=barcolors)

#summary correlation matrix
M <- cor(fifa)
M

#graphical correlation matrix
corrplot(M, method="circle")

```
The EDA process begins by subsetting the data set to include only variables of interest. We maintain Penalties are our dependent variable and include 9 explanatory variables. The summary statistics for Penalties indicate that players' penalties skill range from a low of 5.0 to a high of 92.0 with a mean of 49.0 and a stardard deviation of 15.7. The summary output of the correlation matrix suggest that most variables are correlated in some way to other variables. The graphical display of the correlation matrix visually confirms the correlations. The data may be appropriate for linear regression, but the high correlation associated with some variables may suggest multicollinearity.     
```{r linear, echo=FALSE, include=TRUE}
loadPkg("car")
barcolors = c("green", "violet", "orange", "blue", "pink", "red", "yellow", "cyan")

#add linear reg, calculate mse
reg <- lm(Penalties ~ ., data=fifa)
summary(reg)
vif(reg)

reg.res <- resid(reg)
hist(reg.res, main="Histogram of Residuals", xlab="Residuals", ylab="Frequency", col=barcolors)

```
We build a multiple linear regression model where we regress Penalties on Aggression, Age, Stamina, ShotPower, Balance, BallControl, LongPassing, HeadingAccuracy and Strength. The coefficient on the intercept suggests that the mean skill value for players is 0.76, but coefficient is not statistically significant at any level.

``` {r PCA, echo=FALSE, include=TRUE}
barcolors = c("green", "violet", "orange", "blue", "pink", "red", "yellow", "cyan")

#scale data
prscale <- prcomp(fifa, scale=TRUE)

#summary of scaled data
summary(prscale)

plot(prscale, main="PCA", type = "l", col=barcolors)
```

```{r PCR, echo=FALSE, include=TRUE}
library(pls)

#PCR on training data using CV
smp_size <- floor(0.80 *nrow(fifa))
set.seed(2)
train_ind <- sample(seq_len(nrow(fifa)), size=smp_size)
fifa.train <- fifa[train_ind, ]
fifa.test <- fifa[-train_ind,]
y.test <- fifa.test[,1]
pcr.fit = pcr(Penalties ~., data=fifa.train, scale=TRUE, validation="CV")
summary(pcr.fit)

#plot validation
validationplot(pcr.fit, val.type="MSEP")

#plot coefficients
#coefplot(pcr.fit)

#calculate MSE
pcr.pred <- predict(pcr.fit, fifa.test, ncomp = 6)
mean((pcr.pred - y.test)^2)

#linear regression MSE
mse <- mean(reg$residuals^2)
mse

#fit model
pcr.fit2 <- pcr(Penalties ~.,data=fifa, scale=TRUE, ncomp=6)
summary(pcr.fit2)

#show predicted values vs observed
predplot(pcr.fit2)


```

# Smart Question 3 (CURTIS)
## What variables contribute the most to a goalkeeper’s potential? Age, physical factors, current gk skills, etc...
```{r S3, echo=FALSE, include=TRUE}
#TEST used:  multivariate regression
```

#import data
```{r import}




```

```{r weight height conversion}
library(stringr)
numextract <- function(stringr){str_extract(string, "\\-*\\d+\\.*\\d*")}
#Weight
data$Weight <- as.integer(numextract(data$Weight))
#Height
install.packages("gsubfn")
library(gsubfn)
data$Height <- as.numeric(gsubfn("(\\d)'(\\d+)", ~ as.numeric(x) * 30.48 +
            as.numeric(y) * 2.54, sub('"', '', data$Height)))
data$Height <- as.integer(data$Height)

```

```{r gk}
gk<- subset(data,Position=="GK")
gk <- gk[,colSums(is.na(gk))<nrow(gk)]
gk
```

```{r normality check}
install.packages("car")
library(car)

hist(gk$Potential,main="Histogram for goalkeepers' potential ratings", xlab="rating", col="orange")

qqnorm(gk$Potential, main = "GK's potential ratings Q-Q plot", ylab="rating quantiles", col=c("#ff0000","#00ff00","#0000ff","#ffff00"))
qqline(gk$Potential)

scatterplot(gk$Age, gk$Overall, col = "red", xlab = "Age", ylab = "Current Rating",main = "Age and Current Rating")

scatterplot(gk$Age, gk$Potential, col = "dark green", xlab = "Age", ylab = "Potential Rating",main = "Age and Potential Rating")
```
1. Histogram and Q-Q plot: Goalkeepers' potential ratings are normally distributed, the majority of ratings lies in the 60-70 range.
2. The scatterplot of age and current rating shows a general upward trend, older goalkeepers tend to have greater ratings.
3. The scatterplot of age and potential rating shows a general downward
```{r model1, echo=FALSE}

fit1 <- lm(Potential ~ Age + Height + Weight + Reactions+ Jumping+ GKDiving + GKHandling + GKKicking + GKPositioning + GKReflexes , data = gk)
summary(fit1)
vif(fit1)
fit1
```

```{r model1b, echo=F, include=T}
plot(fit1, col=c("#ff0000","#00ff00","#0000ff","#ffff00"))
```

1. Residuals vs Fitted

This plot shows if residuals have non-linear patterns. There could be a non-linear relationship between predictor variables and an outcome variable and the pattern could show up in this plot if the model doesn’t capture the non-linear relationship. If you find equally spread residuals around a horizontal line without distinct patterns, that is a good indication you don’t have non-linear relationships.

2. Normal Q-Q

This plot shows if residuals are normally distributed. Do residuals follow a straight line well or do they deviate severely? It’s good if residuals are lined well on the straight dashed line.

3. Scale-Location

It’s also called Spread-Location plot. This plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance (homoscedasticity). It’s good if you see a horizontal line with equally (randomly) spread points.

4. Residuals vs Leverage

This plot helps us to find influential cases (i.e., subjects) if any. Not all outliers are influential in linear regression analysis (whatever outliers mean). Even though data have extreme values, they might not be influential to determine a regression line. That means, the results wouldn’t be much different if we either include or exclude them from analysis. They follow the trend in the majority of cases and they don’t really matter; they are not influential. On the other hand, some cases could be very influential even if they look to be within a reasonable range of the values. They could be extreme cases against a regression line and can alter the results if we exclude them from analysis. Another way to put it is that they don’t get along with the trend in the majority of the cases.



# Smart Question 4 (GREGG)
## How do specific Skill Sets/ Characteristics affect a players wage? How about value? Can we say Skills are a good predictor of Wage and value?

```{r r, echo=FALSE, include=TRUE}
## reading data
data <- read.csv("data.csv", check.names = FALSE, stringsAsFactors = FALSE)
```

```{r S44, echo=FALSE, include=TRUE}

## naming rows
wage_skills <- c("Wage","Crossing", "Finishing", "HeadingAccuracy", "ShortPassing", "Volleys", "Dribbling", "Curve", "FKAccuracy", "LongPassing", "BallControl", "Acceleration", "SprintSpeed", "Agility", "Reactions", "Balance", "ShotPower", "Jumping", "Stamina", "Strength", "LongShots", "Aggression", "Interceptions", "Positioning", "Vision", "Penalties", "Composure", "Marking", "StandingTackle", "SlidingTackle", "GKDiving", "GKHandling", "GKKicking", "GKPositioning", "GKReflexes")


value_skills <- c("Value", "Crossing", "Finishing", "HeadingAccuracy", "ShortPassing", "Volleys", "Dribbling", "Curve", "FKAccuracy", "LongPassing", "BallControl", "Acceleration", "SprintSpeed", "Agility", "Reactions", "Balance", "ShotPower", "Jumping", "Stamina", "Strength", "LongShots", "Aggression", "Interceptions", "Positioning", "Vision", "Penalties", "Composure", "Marking", "StandingTackle", "SlidingTackle", "GKDiving", "GKHandling", "GKKicking", "GKPositioning", "GKReflexes")

wage_value <- c("Value","Wage")

```

### ***Clean Up Wage and Value Data 
```{r S4a, echo=FALSE, include=TRUE}
####CLEAN DATA (Wage and Value having same range. remove M and K and period)

#clean data (Removing Pound Sign)
library('stringr')
data_wage_skills <- na.omit(data[c(wage_skills)])
data_value_skills <- na.omit(data[c(value_skills)])

data_wage_skills$Wage <- str_replace(
    data_wage_skills$Wage, # column we want to search
    pattern = '[€]', # what to find
    replacement = '' # what to replace it with
)
data_value_skills$Value <- str_replace(
    data_value_skills$Value, # column we want to search
    pattern = '[€]', # what to find
    replacement = '' # what to replace it with
)
```

```{r S4b, echo=FALSE, include=TRUE}
####Start of Wage Cleanup

data_wage_skills$WageM <- str_replace(
    data_wage_skills$Wage, # column we want to search
    pattern = 'M', # what to find
    replacement = '' # what to replace it with
)
data_wage_skills$WageK <- str_replace(
    data_wage_skills$Wage, # column we want to search
    pattern = 'K', # what to find
    replacement = '' # what to replace it with
)

data_wage_skills$WageMM <- rep(0, length(data_wage_skills$WageM))
data_wage_skills$WageKK <- rep(0, length(data_wage_skills$WageK))

non_alphaM <-grep("[[:alpha:]]",data_wage_skills$WageM, invert = TRUE)
data_wage_skills$WageMM[non_alphaM] <- data_wage_skills$WageM[non_alphaM]

non_alphaK <-grep("[[:alpha:]]",data_wage_skills$WageK, invert = TRUE)
data_wage_skills$WageKK[non_alphaK] <- data_wage_skills$WageK[non_alphaK]

data_wage_skills$WageMM <- as.numeric(data_wage_skills$WageMM)*1000000
data_wage_skills$WageKK <- as.numeric(data_wage_skills$WageKK)*1000

data_wage_skills$Wage <- data_wage_skills$WageMM + data_wage_skills$WageKK

#### End of Wage CLeanup
```

```{r S4c, echo=FALSE, include=TRUE}
#### Start of ValueCleanup

data_value_skills$ValueM <- str_replace(
    data_value_skills$Value, # column we want to search
    pattern = 'M', # what to find
    replacement = '' # what to replace it with
)
data_value_skills$ValueK <- str_replace(
    data_value_skills$Value, # column we want to search
    pattern = 'K', # what to find
    replacement = '' # what to replace it with
)

data_value_skills$ValueMM <- rep(0, length(data_value_skills$ValueM))
data_value_skills$ValueKK <- rep(0, length(data_value_skills$ValueK))

non_alphaVM <-grep("[[:alpha:]]",data_value_skills$ValueM, invert = TRUE)
data_value_skills$ValueMM[non_alphaVM] <- data_value_skills$ValueM[non_alphaVM]

non_alphaVK <-grep("[[:alpha:]]",data_value_skills$ValueK, invert = TRUE)
data_value_skills$ValueKK[non_alphaVK] <- data_value_skills$ValueK[non_alphaVK]

data_value_skills$ValueMM <- as.numeric(data_value_skills$ValueMM)*1000000
data_value_skills$ValueKK <- as.numeric(data_value_skills$ValueKK)*1000

data_value_skills$Value <- data_value_skills$ValueMM + data_value_skills$ValueKK

#summary(data_value_skills$Value)
#head(data_value_skills)
#tail(data_value_skills)
#summary(data_value_skills)
#### End of Value Cleanup
```

```{r S4d, echo=FALSE, include=TRUE}
#More cleanup: 
data_wage_skills <- na.omit(data_wage_skills[c(wage_skills)])
data_value_skills <- na.omit(data_value_skills[c(value_skills)])

```

What is interesting is the skills that affect value and wage the most are reactions, composure, ball control and GK diving. all these made top 5 skills that explain wage and value. These skills are the best predictors of wage and value. 

We can see however that other than these four skills, GK handling seems to explain wage and Short passing seems to explain a Players value.

### Linear Model Wage-Skills
```{r S4e, echo=FALSE, include=TRUE}
wage_lm <- lm(Wage ~ ., data = data_wage_skills)
summary(wage_lm)
```
Top 5 Skills that Explain Wage:
Reactions    - 682.6
Composure    - 212.4
Ball Control - 209.5
GK Handling  - 176.8
GK Diving    - 174.0

### Linear Model Value-Skills
```{r S4f, echo=FALSE, include=TRUE}
value_lm <- lm(Value ~ ., data = data_value_skills)
summary(value_lm)
```
Top 5 Skills that Explain Value:
Reactions     - 208049
Short Passing - 56542
Composure     - 53780
Ball Control  - 52684
GK Diving     - 44531


### Plots of Linear Model Wage-Skills
```{r S4g, echo=FALSE, include=TRUE}
plot(wage_lm)
```

### Plots of Linear Model Value-Skills
```{r S4h, echo=FALSE, include=TRUE}
plot(value_lm)
```

explain what the residuals mean
Check for pre linearmodel , normailty.. etc.. graphs etc..
take the log of the column to normalize it.



### Does Wage and Value Independent??
```{r S4i, include=F}

 
```

##### Chi squared test



```{r s4j, echo=F}

 

```

### PCA Wage-Skills raw and centered
```{r S4k, echo=FALSE, include=TRUE}
PCA_wage_skills_C <- prcomp(data_wage_skills, center = TRUE,scale. = TRUE) #center
PCA_wage_skills_R <- prcomp(data_wage_skills, center = TRUE,scale. = FALSE) #raw
summary(PCA_wage_skills_C)
summary(PCA_wage_skills_R)
```

### PCA Value-Skills raw and centered
```{r S4l, echo=FALSE, include=TRUE}
PCA_value_skills_C <- prcomp(data_value_skills, center = TRUE,scale. = TRUE) #center
PCA_value_skills_R <- prcomp(data_value_skills, center = TRUE,scale. = FALSE) #raw
summary(PCA_value_skills_C)
summary(PCA_value_skills_R)
```


WE then performed a PCA analysis to determine the components needed to explain 80% of the data

# Smart Question 5 (JAY)
## How do physical factors (age, preferred foot, overall skill, international reputation, position in the field, weight, and height) help the soccer professionals to get wage for higher 100,000 Euro per week?
```{r S5, echo=FALSE, include=TRUE}
#Wage(Factor) – 1 (Higher 100k euro per week), 0 (lower 100k euro per week).
#Age (Integer)
#Foot (Factor)
#Skill (Integer)
#Weight (Integer)
#Height (Integer)
#International reputation (Factor) – 5 level.
#Position (Factor) – 4 types, including Goalkeeper, defense, midfield, and attack.
#=======
## Chapter 7: Earning higher 100,000 Euro per week of soccer players (Jay)

### 7.1 SMART Question
#### How do physical factors help the soccer professionals to get wage for higher 100,000 Euro per week?
```

```{r import fifa, include=F}
#import data
Dataa <- read.csv("data.csv")
fifaOri <- select(Dataa, Age, Overall, Wage, Preferred.Foot, Position, Height, Weight)

```

### 7.2 Exploratory Data Analysis
In this section, we perform the exloratory data analysis (EDA) on several numerical variables in the dataset. After assessing some of the characteristics of those variables, we decided to clean the data by omitting outliers and NA values. 

#### 7.2.1. Data tranformation and Descriptive Statistics
##### Data tranformation 
In this chapter, we use logistic regression with 7 variables including age, skill level, wage, preferred foot, position, height, and weight. However, we have not cleaned the data yet.

The original data are below:

```{r EDA11, echo=F}
str(fifaOri)

```

```{r clean data, include=F}
#clean data
#wage
library(stringr)
numextract <- function(string){ 
  str_extract(string, "\\-*\\d+\\.*\\d*")
} 
fifaOri$Wage <- as.integer(numextract(fifaOri$Wage))
fifaOri$Wage_dummy <- as.factor(ifelse(fifaOri$Wage > 99, 1, 0))
#Foot - cleaned
y <- as.factor(fifaOri$Preferred.Foot)
levels(y) <- list(Left  = c("Left"), 
                  Right = c("Right"))
fifaOri <- mutate(fifaOri, Preferred.Foot = y)
#age - cleaned
#skill - cleaned
#Weight
fifaOri$Weight <- as.integer(numextract(fifaOri$Weight))
#Height 

library(gsubfn)

fifaOri$Height <- as.numeric(gsubfn("(\\d)'(\\d+)", ~ as.numeric(x) * 30.48 + 
            as.numeric(y) * 2.54, sub('"', '', fifaOri$Height)))
fifaOri$Height <- as.integer(fifaOri$Height)
#position
x <- as.factor(fifaOri$Position)
levels(x) <- list(GK  = c("GK"), 
                  DEF = c("LWB", "LB", "CB", "RB", "RWB", "LCB", "RCB"), 
                  MID = c("CM", "LDM", "LAM", "RDM", "RAM", "CDM", "CAM", "LM", "RM", "LCM", "RCM"), 
                  FWD = c("CF", "ST", "LW", "RW", "LF", "RF", "LS", "RS"))
fifaOri <- mutate(fifaOri, Position = x)
#Region 
#library(countrycode)
#fifa$Nationality <- as.factor(fifa$Nationality)
#fifa$region <- as.factor(countrycode(sourcevar = fifa[, "Nationality"],
                          #  origin = "country.name",
                           # destination = "continent"))
#fifa <- mutate(fifa, Position = x)

str(fifaOri)
head(fifaOri)


```

After transforming some variables, we got the new data. There are 4 numeric variables (age, skill level, height, and weight) and 3 categorical variables (Wage_dummy, position, and preferred foot)    

The new data are below:

```{r EDA1, echo=F}
fifaQQ <- select(fifaOri, Age, Overall, Height, Weight, Position, Preferred.Foot, Wage_dummy)
str(fifaQQ)

```

##### Descriptive Statistics

The descriptive statistics are presented below:

```{r EDA2, echo=F}
summary(fifaQQ)

```

According to the above statistics, it can be seen that mean and median of 4 numeric variables are very close. However, There are a lot of missing values (NAs) in height, weight, position, and preferred foot.

#### 7.2.2. Normality (Q-Q plots)

In this step, we need to check normality for 4 numeric variable, including age, skill level, height, and weight. 

```{r EDA3, echo=F}
par(mfrow=c(2,2))
qqnorm(fifaQQ$Age, main = "Age Q-Q plot", ylab="Age quantiles")
qqline(fifaQQ$Age, col = "red")
qqnorm(fifaQQ$Overall, main = "Skill level Q-Q plot", ylab="Skill level quantiles")
qqline(fifaQQ$Overall, col = "red")
qqnorm(fifaQQ$Height, main = "Height Q-Q plot", ylab="Height quantiles")
qqline(fifaQQ$Height, col = "red")
qqnorm(fifaQQ$Weight, main = "Weight Q-Q plot", ylab="Weight quantiles")
qqline(fifaQQ$Weight, col = "red")

```

According to the above Q-Q plots, these four numeric variables are not far from normal distribution. However, the tails in each Q-Q plot indicate that the data have the outliers. Therefore, removing outliers process is required before doing an analysis in the next step.

```{r out, include=F}
#Create a function to eliminate outliners.
outlierKD <- function(dt, var, rmv=NULL) { 
     var_name <- eval(substitute(var),eval(dt))
     na1 <- sum(is.na(var_name))
     m1 <- mean(var_name, na.rm = T)
     sd1 <- sd(var_name,na.rm = T)
     par(mfrow=c(2, 2), oma=c(0,0,3,0))
     boxplot(var_name, main="With outliers")
     hist(var_name, main="With outliers", xlab=NA, ylab=NA)
     outlier <- boxplot.stats(var_name)$out
     mo <- mean(outlier)
     var_name <- ifelse(var_name %in% outlier, NA, var_name)
     boxplot(var_name, main="Without outliers")
     hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
     title("Outlier Check", outer=TRUE)
     na2 <- sum(is.na(var_name))
     cat("Outliers identified:", na2 - na1, "n")
     cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "n")
     cat("Mean of the outliers:", round(mo, 2), "n")
     m2 <- mean(var_name, na.rm = T)
     cat("Mean without removing outliers:", round(m1, 2), "n")
     cat("Mean if we remove outliers:", round(m2, 2), "n")
     #
     if(is.null(rmv)) { 
       response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ") 
     } else {
       if (rmv=='y'|rmv=='yes'|rmv=='Y'|rmv=='Yes'|rmv=='YES'|rmv==TRUE ) { response = 'y' } else { response = 'n' }
     }
     #
     if(response == "y" | response == "yes"){
          dt[as.character(substitute(var))] <- invisible(var_name)
          assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
          cat("Outliers successfully removed", "n")
          return(invisible(dt))
     } else{
          cat("Nothing changed", "n")
          return(invisible(var_name))
     }
}
```

```{r out2, include=F}
outlierKD(fifaQQ, Age,'y') #Eliminate outliers.
outlierKD(fifaQQ, Overall,'y') #Eliminate outliers.
outlierKD(fifaQQ, Weight,'y') #Eliminate outliers.
outlierKD(fifaQQ, Height,'y') #Eliminate outliers.
fifaNew <- na.omit(fifaQQ) #Eliminate NAs
summary(fifaNew) #Check the summary statistics of fifa
str(fifaNew)

```

### 7.3 Pre-Logistic Regression

#### Does the data support that “Age”, "Preferred foot", "Overall skill level", "Preferred position", "Weight", and "Height" affect “Wage”?

#### 7.3.1 Age VS Wage

To study the effects on wage by the age (one categorical variable and one qualitative variable, respectively), we can create two-way contingency table of the outcome and predictors.

```{r 4.3.1, include=F}
wageagetable = xtabs(~ Wage_dummy + Age, data = fifaNew)

```

##### Chi squared test

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).

```{r 4.3.1a, echo=F}
chisqres_Q1 = chisq.test(wageagetable)
chisqres_Q1

```

From the small p-value of `r chisqres_Q1$p.value`, we reject the null hypothesis that the "Wage" and  "Age" are independent. Therefore, the data supports “age” may have an effect on “Wage”. 

#### 7.3.2 Preferred foot VS Wage

To study the effects on wage by preferred foot (both of them categorical variables), we can create two-way contingency table of the outcome and predictors.

```{r 4.3.2, include=F}
wagefoottable = xtabs(~ Wage_dummy + Preferred.Foot, data = fifaNew)

```

##### Chi squared test

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).

```{r 4.3.2a, echo=F}
chisqres_Q2 = chisq.test(wagefoottable)
chisqres_Q2

```

From the large p-value of `r chisqres_Q2$p.value`, we fall to reject the null hypothesis that the "Wage" and  "Foot" are independent. Therefore, the data supports “Prefered foot” might not have an effect on “Wage”. 

##### 7.3.3 Wage VS Overall skill level

To study the effects on wage by the skill level (one categorical variable and one qualitative variable, respectively), we can create two-way contingency table of the outcome and predictors.

```{r 4.3.3, include=F}
wageskilltable = xtabs(~ Wage_dummy + Overall, data = fifaNew)

```

##### Chi squared test

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).

```{r 4.3.3a, echo=F}
chisqres_Q3 = chisq.test(wageskilltable)
chisqres_Q3

```

From the small p-value of `r chisqres_Q3$p.value`, we reject the null hypothesis that the "Wage" and  "Skill level" are independent. Therefore, the data supports “Skill level” might have an effect on “Wage”.

##### 7.3.4 Wage VS Height

To study the effects on wage by the height (one categorical variable and one qualitative variable, respectively), we can create two-way contingency table of the outcome and predictors.  

```{r 4.3.4, include=F}
wageheitable = xtabs(~ Wage_dummy + Height, data = fifaNew)

```

##### Chi squared test

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).

```{r 4.3.4a, echo=F}
chisqres_Q4 = chisq.test(wageheitable)
chisqres_Q4

```

From the large p-value of `r chisqres_Q4$p.value`, we fall to reject the null hypothesis that the "Wage" and  "Height" are independent. Therefore, the data supports “Height” might not have an effect on “Wage”.


#### 7.3.5 Wage VS Weight

To study the effects on wage by the weight (one categorical variable and one qualitative variable, respectively), we can create two-way contingency table of the outcome and predictors.  

```{r 4.3.5, include=F}
wageweitable = xtabs(~ Wage_dummy + Weight, data = fifaNew)

```

##### Chi squared test

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).

```{r 4.3.5a, echo=F}
chisqres_Q5 = chisq.test(wageweitable)
chisqres_Q5

```

From the large p-value of `r chisqres_Q5$p.value`, we fall to reject the null hypothesis that the "Wage" and  "weight" are independent. Therefore, the data supports “Weight” might not have an effect on “Wage”.

#### 7.3.6 Wage VS Perferred position in the field

To study the effects on wage by the position (two categorical variables), we can create two-way contingency table of the outcome and predictors.

```{r 4.3.6, include=F}
wagepositable = xtabs(~ Wage_dummy + Position, data = fifaNew)

```

##### Chi squared test

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).

```{r 4.3.6a, echo=F}
chisqres_Q6 = chisq.test(wagepositable)
chisqres_Q6
#>>>>>>> c62f819f41a0539212ee1fa7fe260fdac0397553

```

From the small p-value of `r chisqres_Q6$p.value`, we reject the null hypothesis that the "Wage" and  "Position" are independent at the 1% significance level. Therefore, the data supports “Position” might have an effect on “Wage”.

### 7.4 Logistic Regression

Let us now turn our attention to logistic regression models. We run the Wage model including age, preferred.Foot, overall skill level, preferred position in the field, weight, and height.

```{r 4.4, include=F}
wageLogit <- glm(Wage_dummy ~ Age + Preferred.Foot + Overall + Position + Weight + Height , data = fifaNew, family = "binomial")

```

#### We can see the summary of the logistic regression model here:  
```{r 4.4a, echo=F}
summary(wageLogit)
```
#### Model interpretation: 

##### The age effect on wage
According to the above regression results, the cofficient on age indicates that for every one year increases in age, ln(odds-ratio) of wage at higher 100,000 Euro per week level decreases by 0.06. In other word, it means that the young player have more opportunity to earn higher 100k Euro per week than the olders. Furthermore, it is statistically significant.

##### The preferred foot effect on wage
For preferred foot: use left foot as baseline, ln(odds-ratio) of wage at higher 100,000 Euro per week level deceases by 0.02 when changing from left to right foot. So, it is likely that the left foot players have more the opportunity to earn higher 100,000 Euro per week than the right foot player. However, it is not statistically significant. 

##### The skill level effect on wage
The cofficient on skill level indicates that for every one level increases in overall skill, ln(odds-ratio) of wage at higher 100,000 Euro per week level increase by 0.72. In other word, it means that the high skill players have more opportunity to earn higher 100k Euro per week than the low skill players. In addition, it is statistically significant.

##### The effect of position of the player in the field on wage 
For position: use Goalkeeper as baseline, ln(odds-ratio) of wage at higher 100,000 Euro per week level increases by 1.42 when changing from Goalkeeper to Defender. And, ln(odds-ratio) of higher 100,000 euro wage increases by 1.35 when changing from Goalkeeper to Midfielder. Finally, ln(odds-ratio) of higher 100,000 euro wage increases by 1.49 when changing from Goalkeeper to Forward. It is likely that the opportunity to earn higher 100k Euro per week will increase if the preferred position of soccer players are far from goalkeeper. In addition, the case is statistically significant. 

##### The weight effect on wage
The cofficient on weight indicates that for every one lbs increases in weight, ln(odds-ratio) of wage at higher 100,000 Euro per week level decreases by 0.006. In other word, it means that the low weight players have more opportunity to earn higher 100k Euro per week than the high weight players. However, this case is not statistically significant.

##### The height effect on wage
The cofficient on height indicates that for every one centimeter (CM) increases in height, ln(odds-ratio) of wage at higher 100,000 Euro per week level decreases by 0.002. In other word, it seems that the short players have more opportunity to earn higher 100k Euro per week than the tall players height. However, it is not statistically significant.

### 7.5 Model evaluation

#### 7.5.1. ROC curve and AUC
Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC) measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The area-under-curve is always between 0.5 and 1. Values higher than 0.8 is considered good model fit.  

```{r 4.5.1, include=F}
library(pROC) # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(wageLogit, type = c("response"))
fifaNew$prob=prob
h <- roc(Wage_dummy~prob, data=fifaNew)
auc(h) # area-under-curve prefer 0.8 or higher.

```

The result is shown here: 

```{r 4.5.1a, echo=F}
plot(h)
# detach("package:pROC", unload = T) # good habit to remove unload packages no longer needed 
```

We have here the area-under-curve of `r auc(h)`, which is higher than 0.8. This indicates the model is really a good fit, and all the coefficients are significant.  

#### 7.5.2. McFadden  
McFadden is another evaluation tool we can use on logitistic regressions. This is part of what is called pseudo-R-squared values for evaluation tests.

```{r 4.5.2, include=F}
library(pscl) # use pR2( ) function to calculate McFadden statistics for model eval
wageLogitpr2 = pR2(wageLogit)
wageLogitpr2
# detach("package:pscl", unload = T) # good habit to remove unload packages no longer needed 
```

In this case, the McFadden value is `r wageLogitpr2['McFadden']`, which is analgous to the coefficient of determination R$2$, only about 5.7% of the variations in y is explained by the explanatory variables in the model. 

